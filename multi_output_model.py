# -*- coding: utf-8 -*-
"""Multi_Output_Model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1cWFtXQZuKLBayc6GKWTB3tzfOZyp79Ln

# Importing Libraries
"""

import tensorflow as tf
from tensorflow import keras
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
from keras.models import Model
from keras.layers import Dense, Input
from sklearn.model_selection import train_test_split

"""#EDA and Data Preparation"""

# Fetching the Dataset
!pip install ucimlrepo
from ucimlrepo import fetch_ucirepo
energy_efficiency = fetch_ucirepo(id=242)

X = energy_efficiency.data.features
y = energy_efficiency.data.targets
df_X = pd.DataFrame(X)
df_y = pd.DataFrame(y)
df = pd.concat([df_X,df_y],axis=1)

def format_output(data):
  y1 = data.pop('Y1')
  y1 = np.array(y1)
  y2 = data.pop('Y2')
  y2 = np.array(y2)
  return y1, y2

def norm_feature(data):
  # Normalized feature variables
  data_stats = data.describe().transpose()
  data = (data - data_stats['mean'])/data_stats['std']

  return data

def dataset():
  """
  Return Normalized feature variables,
  Train and Test Dataset
  """
  print(f"--Shape of DataFrame: {df.shape}--")
  train, test = train_test_split(df, test_size=0.2)

  y_train = format_output(train)
  y_test = format_output(test)

  # Normalized feature variables
  X_train = norm_feature(train)
  X_test = norm_feature(test)
  print(f"---Training Points: {X_train.shape}---")
  print(f"---Test Points: {X_test.shape}---")
  return X_train, X_test, y_train, y_test

X_train, X_test, y_train, y_test = dataset()

input_layer = tf.keras.layers.Input(shape=(len(X_train.columns), ))
first_dense = tf.keras.layers.Dense(units = 128, activation='relu')(input_layer)
second_dense= tf.keras.layers.Dense(units= 128, activation = 'relu')(first_dense)

y1_output = tf.keras.layers.Dense(units = 1, name = 'y1_output')(second_dense)

third_dense = tf.keras.layers.Dense(units = 64, activation = 'relu')(second_dense)
y2_output = tf.keras.layers.Dense(units = 1, name = 'y2_output')(third_dense)

model = tf.keras.Model(inputs = input_layer, outputs= [y1_output, y2_output])


#Configure parameters
#We specify the optimizer as well as the loss and metrics for each output.
optimizer = tf.keras.optimizers.SGD(learning_rate= 0.001)
model.compile(optimizer = optimizer,
              loss = {'y1_output':'mse', 'y2_output':'mse'},
              metrics = {
                  'y1_output': tf.keras.metrics.RootMeanSquaredError(),
                  'y2_output': tf.keras.metrics.RootMeanSquaredError()
              })

history = model.fit(X_train, y_train,
                    epochs=500, batch_size=10, validation_data=(X_test, y_test))

loss, Y1_rmse, Y2_rmse = model.evaluate(x=X_test, y=y_test)
print("Loss = {}, Y1_rmse = {}, Y2_rmse = {}".format(loss, Y1_rmse, Y2_rmse))

Y_pred = model.predict(X_test)
plt.scatter(y_test[0], Y_pred[0])
plt.xlabel('True Values')
plt.ylabel('Prediction')
plt.title("Ground Truth Vs Y1 Prediction ")
plt.show()

plt.scatter(y_test[1], Y_pred[1])
plt.xlabel('True Values')
plt.ylabel('Prediction')
plt.title("Ground Truth Vs Y2 Prediction ")
plt.show()

#An Example
test_point = [[0.98, 514.50, 294, 110.25, 7, 4,0.10,2]]
Y1, Y2  = model.predict((np.array(test_point)))
print(f"Predicted Value Y1 and Y2: {Y1, Y2}")